import json
import os
import re
import time
import datetime
import traceback
from collections import Counter
from tarfile import data_filter

from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register
from astrbot.api import logger


# è§£æJSON
def _parse_llm_json(text: str) -> dict:
    """
    å°è¯•ä» LLM çš„å›å¤ä¸­æå–å¹¶è§£æ JSONã€‚
    æ”¯æŒå¤„ç† markdown ä»£ç å—ã€å‰åæ— å…³æ–‡æœ¬ç­‰æƒ…å†µã€‚
    """
    try:
        # 1. å°è¯•ç›´æ¥è§£æï¼ˆä¸‡ä¸€ LLM å¾ˆå¬è¯ï¼‰
        return json.loads(text)
    except json.JSONDecodeError:
        pass

    try:
        # 2. ä½¿ç”¨æ­£åˆ™æå–ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª } ä¹‹é—´çš„å†…å®¹
        # [\s\S] åŒ¹é…ä»»æ„å­—ç¬¦åŒ…æ‹¬æ¢è¡Œç¬¦ï¼Œ* è´ªå©ªåŒ¹é…ç¡®ä¿æ‹¿åˆ°å®Œæ•´çš„ JSON å¯¹è±¡
        match = re.search(r"\{[\s\S]*\}", text)
        if match:
            json_str = match.group()
            return json.loads(json_str)
    except json.JSONDecodeError:
        pass

    # 3. å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸æˆ–è¿”å›ç©º
    raise ValueError("æ— æ³•ä» LLM å›å¤ä¸­æå–æœ‰æ•ˆçš„ JSON æ•°æ®")


@register("group_summary", "æ£’æ£’ç³–", "ç¾¤èŠæ€»ç»“", "1.1.3")
class GroupSummaryPlugin(Star):
    def __init__(self, context: Context, config: dict = None):
        super().__init__(context)
        self.config = config or {}
        self.max_msg_count = self.config.get("max_msg_count", 2000)
        self.max_query_rounds = self.config.get("max_query_rounds", 10)
        self.bot_name = self.config.get("bot_name", "çº±ç»‡")
        self.msg_token_limit = self.config.get("token_limit", 6000)
        # è·å–å½“å‰æ–‡ä»¶ (main.py) æ‰€åœ¨çš„ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        # æ‹¼æ¥æ¨¡æ¿æ–‡ä»¶è·¯å¾„: group_summary/templates/report.html
        template_path = os.path.join(current_dir, "templates", "report.html")
        try:
            with open(template_path, "r", encoding="utf-8") as f:
                self.html_template = f.read()
            logger.info(f"ç¾¤èŠæ€»ç»“:æˆåŠŸåŠ è½½ç¾¤èŠæ€»ç»“æ¨¡æ¿: {template_path}")
        except FileNotFoundError:
            logger.error(f"ç¾¤èŠæ€»ç»“:æœªæ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶: {template_path}")
            # è®¾ç½®ä¸€ä¸ªç®€å•çš„å…œåº•æ¨¡æ¿ï¼Œé˜²æ­¢å´©æºƒ
            self.html_template = "<h1>Template Not Found</h1>"

    async def fetch_group_history(self, bot, group_id: str, hours_limit: int = 24):
        """åˆ†é¡µè·å–ç¾¤èŠå†å²æ¶ˆæ¯"""
        all_messages = []
        message_seq = 0
        cutoff_time = time.time() - (hours_limit * 3600)

        logger.info(f"ç¾¤èŠæ€»ç»“:å¼€å§‹è·å–ç¾¤ {group_id} æ¶ˆæ¯ï¼Œç›®æ ‡ä¸Šé™: {self.max_msg_count}æ¡ / {self.max_query_rounds}è½®")

        for round_idx in range(self.max_query_rounds):
            # 1. æ£€æŸ¥æ€»æ•°æ˜¯å¦è¶…æ ‡
            if len(all_messages) >= self.max_msg_count:
                break

            try:
                # 2. æ„é€  API å‚æ•°
                params = {
                    "group_id": group_id,
                    "count": 200,
                    "message_seq":message_seq,
                    "reverseOrder": True,
                }
                logger.info(f"ç¾¤èŠæ€»ç»“:Round {round_idx+1}: è·å–å‚æ•°: {params}")
                # 3. è°ƒç”¨ API
                resp: dict = await bot.api.call_action("get_group_msg_history", **params)

                round_messages = resp["messages"]
                if not round_messages:
                    break
                batch_msgs = round_messages
                # æ›´æ–° seq ä»¥è·å–æ›´æ—©çš„æ¶ˆæ¯
                # å‡è®¾è¿”å›çš„æ¶ˆæ¯æ˜¯æŒ‰æ—¶é—´å€’åºæˆ–æ­£åºï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°æœ€â€œæ—§â€çš„ä¸€æ¡çš„ID
                # NapCat get_group_msg_history é€šå¸¸è¿”å›çš„æ˜¯ [oldest ... newest]
                # ç¿»é¡µæ—¶ï¼Œé€šå¸¸å–æœ€æ—§ä¸€æ¡çš„ seq ä½œä¸ºä¸‹ä¸€æ¬¡çš„èµ·ç‚¹
                oldest_msg_time = batch_msgs[-1].get("time", 0)
                newest_msg_time = batch_msgs[0].get("time", 0)
                logger.info(f"ç¾¤èŠæ€»ç»“:Round {round_idx+1}: æœ€æ—§æ¶ˆæ¯æ—¶é—´: {oldest_msg_time}")
                logger.info(f"ç¾¤èŠæ€»ç»“:Round {round_idx+1}: æœ€æ–°æ¶ˆæ¯æ—¶é—´: {newest_msg_time}")
                # æ¥å£ä¸å…¼å®¹çš„é¢„é˜²ä»£ç 
                message_seq = round_messages[-1]["message_seq"]
                if oldest_msg_time > newest_msg_time:
                    message_seq = batch_msgs[0]["message_seq"]
                    oldest_msg_time = newest_msg_time
                logger.info(f"ç¾¤èŠæ€»ç»“:æœ¬æ¬¡è·å–åˆ°çš„æœ€æ—§ä¸€æ¡message_seq:{message_seq}")
                logger.info(f"ç¾¤èŠæ€»ç»“:Round {round_idx+1}: è·å–åˆ° {len(batch_msgs)} æ¡æ¶ˆæ¯")
                if not batch_msgs:
                    break # æ²¡æœ‰æ›´å¤šæ¶ˆæ¯äº†

                # NapCat è¯·æ±‚çš„å€’æ•°æ•°æ®ï¼Œæ˜¯æ–°->æ—§çš„é¡ºåº
                # æˆ‘ä»¬éœ€è¦æŠŠè¿™æ‰¹æ¶ˆæ¯åŠ åˆ°æ€»åˆ—è¡¨é‡Œ
                # æ³¨æ„ï¼šå¦‚æœæ˜¯ç¿»é¡µè·å–ï¼Œæ–°è·å–çš„æ‰¹æ¬¡åº”è¯¥æ”¾åœ¨æ€»åˆ—è¡¨çš„æœ€å‰é¢ï¼Œæˆ–è€…æœ€åç»Ÿä¸€æŒ‰æ—¶é—´æ’åº
                all_messages.extend(batch_msgs)

                # å¦‚æœè¿™ä¸€è½®æŠ“å–çš„æœ€æ—§æ¶ˆæ¯éƒ½è¿˜åœ¨ cutoff ä¹‹å‰ï¼Œè¯´æ˜å·²ç»æŠ“å¤Ÿäº†æ—¶é—´èŒƒå›´
                if oldest_msg_time < cutoff_time:
                    # è™½ç„¶è¿™ä¸€æ‰¹é‡Œå¯èƒ½æœ‰ä¸€éƒ¨åˆ†æœ‰æ•ˆï¼Œä½†ä¸‹ä¸€è½®è‚¯å®šéƒ½æ˜¯æ— æ•ˆçš„äº†ï¼Œæ ‡è®°ç»“æŸ
                    break

                # ç®€å•çš„è¿›åº¦æ—¥å¿—
                logger.info(f"ç¾¤èŠæ€»ç»“:Round {round_idx+1}: è·å–åˆ° {len(batch_msgs)} æ¡æ¶ˆæ¯")

            except Exception as e:
                logger.error(f"ç¾¤èŠæ€»ç»“:Error: {traceback.format_exc()}")
                logger.info(f"ç¾¤èŠæ€»ç»“:Fetch loop error: {e}")
                break

        return all_messages

    def process_messages(self, messages: list, hours_limit: int = 24):
        """çº¯ Python ç»Ÿè®¡æ•°æ®"""
        cutoff_time = time.time() - (hours_limit * 3600)
        logger.info(f"ç¾¤èŠæ€»ç»“:å¼€å§‹å¤„ç† {len(messages)} æ¡æ¶ˆæ¯ï¼ŒèŠå¤©æˆªæ­¢æ—¶é—´æˆ³ä¸º: {cutoff_time} ")
        valid_msgs = []
        user_counter = Counter()
        trend_counter = Counter()
        filter_date_count = 0
        filter_sys_msg_count = 0
        for msg in messages:
            ts = msg.get("time", 0)
            if ts < cutoff_time:
                filter_date_count += 1
                continue

            # è¿‡æ»¤QQè½¬å‘å’Œå›¾ç‰‡ä¿¡æ¯
            if "[CQ:" in msg.get("raw_message"):
                filter_sys_msg_count += 1
                continue

            sender = msg.get("sender", {})
            nickname = sender.get("card") or sender.get("nickname") or "æœªçŸ¥ç”¨æˆ·"
            content = msg.get("raw_message") or ""

            # 1. æ”¶é›†æœ‰æ•ˆæ¶ˆæ¯
            valid_msgs.append({
                "time": ts,
                "name": nickname,
                "content": content
            })

            # 2. ç»Ÿè®¡ç”¨æˆ·å‘è¨€æ•°
            user_counter[nickname] += 1

            # 3. ç»Ÿè®¡å°æ—¶è¶‹åŠ¿
            hour_str = datetime.datetime.fromtimestamp(ts).strftime("%H")
            trend_counter[str(int(hour_str))] += 1

        # æ•´ç† Top 5
        top_users = [{"name": name, "count": count} for name, count in user_counter.most_common(5)]

        # æ•´ç† LLM æ—¥å¿—æ–‡æœ¬
        chat_log = "\n".join([
            f"[{datetime.datetime.fromtimestamp(m['time']).strftime('%Y.%m.%d %H:%M')}] {m['name']}: {m['content']}"
            for m in valid_msgs
        ])
        logger.info(f"ç¾¤èŠæ€»ç»“:å…±è·å–åˆ°{len(valid_msgs)}æ¡æœ‰æ•ˆæ¶ˆæ¯,è¿‡æ»¤{filter_date_count}æ¡æ—¶é—´è¶…å‡ºé™åˆ¶æ¶ˆæ¯,è¿‡æ»¤{filter_sys_msg_count}æ¡ç³»ç»Ÿæ¶ˆæ¯")
        return valid_msgs, top_users, dict(trend_counter), chat_log



    # --- æ ¸å¿ƒé€»è¾‘ç”Ÿæˆå™¨ (ä¾› Command å’Œ Tool å¤ç”¨) ---
    async def _summary_logic(self, event: AstrMessageEvent, hours: int = 24):
        group_id = event.get_group_id()
        if not group_id:
            yield event.plain_result("âš ï¸ åªæœ‰åœ¨ç¾¤èŠä¸­æ‰èƒ½ä½¿ç”¨æ€»ç»“åŠŸèƒ½å“¦ã€‚")
            return

        yield event.plain_result(f"ğŸŒ± æ­£åœ¨è¿æ¥ç¥ç»äº‘ç«¯ï¼Œå›æº¯æœ€è¿‘ {hours} å°æ—¶çš„è®°å¿†...")

        try:
            group_info = await event.bot.api.call_action("get_group_info", group_id=group_id)
        except:
            group_info = {"group_name": "æœªçŸ¥ç¾¤èŠ"}

        # 1. è·å–æ¶ˆæ¯
        raw_messages = await self.fetch_group_history(event.bot, group_id, hours_limit=hours)
        if not raw_messages:
            yield event.plain_result("âš ï¸ æ— æ³•è·å–å†å²æ¶ˆæ¯ï¼Œå¯èƒ½æ˜¯APIå—é™æˆ–è®°å½•ä¸ºç©ºã€‚")
            return

        # 2. å¤„ç†æ•°æ®
        valid_msgs, top_users, trend, chat_log = self.process_messages(raw_messages, hours_limit=hours)
        if not valid_msgs:
            yield event.plain_result(f"åœ¨æœ€è¿‘ {hours} å°æ—¶å†…æ²¡æœ‰å‘ç°èŠå¤©è®°å½•ã€‚")
            return

        if len(chat_log) > self.msg_token_limit:
            logger.warning(f"ç¾¤èŠæ€»ç»“:LLM æ—¥å¿—é•¿åº¦è¶…è¿‡é™åˆ¶:{len(chat_log)}ï¼Œå·²æˆªæ–­ã€‚")
            chat_log = chat_log[:self.msg_token_limit]

        # 3. LLM Prompt
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªç¾¤èŠè®°å½•å‘˜â€œ{self.bot_name}â€ã€‚è¯·æ ¹æ®ä»¥ä¸‹çš„ç¾¤èŠè®°å½•ï¼ˆæœ€è¿‘{hours}å°æ—¶ï¼‰ï¼Œç”Ÿæˆä¸€ä»½æ€»ç»“æ•°æ®ã€‚

        ã€è¦æ±‚ã€‘ï¼š
        1. åˆ†æ 3-8 ä¸ªä¸»è¦è¯é¢˜ï¼Œæ¯ä¸ªè¯é¢˜åŒ…å«ï¼šæ—¶é—´æ®µï¼ˆå¦‚2026-01-15 10:00 ~ 2026-01-15 11:00ï¼‰å’Œç®€çŸ­å†…å®¹ã€‚
        2. å†™ä¸€æ®µâ€œ{self.bot_name}çš„æ‚„æ‚„è¯â€ä½œä¸ºæ€»ç»“ï¼Œé£æ ¼æ¸©æš–ã€æ„Ÿæ€§ã€‚
        3. ä¸¥æ ¼è¿”å› JSON æ ¼å¼ï¼š{{"topics": [{{"time_range": "...", "summary": "..."}}],"closing_remark": "..."}}

        ã€èŠå¤©è®°å½•ã€‘ï¼š
        {chat_log}
        """

        yield event.plain_result(f"â˜ï¸ å·²è·å– {len(valid_msgs)} æ¡æ¶ˆæ¯ï¼Œæ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        logger.info(f"ç¾¤èŠæ€»ç»“:æœ¬æ¬¡è·å–çš„èŠå¤©è®°å½•ï¼š{chat_log}")
        # 4. è°ƒç”¨ LLM
        try:
            provider = self.context.get_provider_by_id(
                self.config.get("provider_id")) or self.context.get_using_provider()
            if not provider:
                yield event.plain_result("âŒ æœªé…ç½®ç”¨äºæ–‡æœ¬ç”Ÿæˆä»»åŠ¡çš„ LLM æä¾›å•†ã€‚")
                return

            response = await provider.text_chat(prompt, session_id=None)
            logger.info(f"ç¾¤èŠæ€»ç»“:LLM åŸå§‹å›å¤: {response.completion_text}")  # å»ºè®®ä¿ç•™æ—¥å¿—ä»¥ä¾¿è°ƒè¯•
            analysis_data = _parse_llm_json(response.completion_text)
        except Exception as e:
            logger.error(f"ç¾¤èŠæ€»ç»“:Traceback Error: {traceback.format_exc()}")
            logger.error(f"ç¾¤èŠæ€»ç»“:LLM Error: {e}")
            analysis_data = {"topics": [], "closing_remark": "çº±ç»‡å§å§æœ‰ç‚¹ç´¯äº†ï¼Œæ²¡èƒ½å†™å‡ºæ€»ç»“..."}

        # 5. æ¸²æŸ“
        try:
            render_data = {
                "date": datetime.datetime.now().strftime("%Y.%m.%d"),
                "top_users": top_users,
                "trend": trend,
                "topics": analysis_data.get("topics", []),
                "summary_text": analysis_data.get("closing_remark", ""),
                "group_name": group_info.get("group_name", "ç¾¤èŠ"),
                "bot_name": self.bot_name
            }
            options = {"quality": 95, "device_scale_factor_level": "ultra", "viewport_width": 500}
            img_result = await self.html_render(self.html_template, render_data, options=options)
            yield event.image_result(img_result)
        except Exception as e:
            logger.error(f"ç¾¤èŠæ€»ç»“:Render Error: {traceback.format_exc()}")
            yield event.plain_result(f"âŒ æ¸²æŸ“å¤±è´¥: {e}")

    # --- 1. æŒ‡ä»¤å…¥å£ ---
    @filter.command("æ€»ç»“ç¾¤èŠ")
    @filter.permission_type(filter.PermissionType.ADMIN)
    @filter.event_message_type(filter.EventMessageType.GROUP_MESSAGE)
    async def summarize_group(self, event: AstrMessageEvent):
        """
        æ‰‹åŠ¨æŒ‡ä»¤ï¼š/æ€»ç»“ç¾¤èŠ
        """
        async for result in self._summary_logic(event, hours=24):
            yield result

    # --- 2. Tool (Function Call) å…¥å£ ---
    @filter.llm_tool(name="group_summary_tool")
    async def call_summary_tool(self, event: AstrMessageEvent, hours: int = 24):
        """
        æ€»ç»“å½“å‰ç¾¤èŠã€‚å½“ç”¨æˆ·è¯¢é—®â€œä»Šå¤©ç¾¤é‡Œå‘ç”Ÿäº†ä»€ä¹ˆâ€ã€â€œæ€»ç»“ä¸€ä¸‹ç¾¤èŠâ€ã€â€œå¤§å®¶åœ¨èŠä»€ä¹ˆâ€æ—¶è°ƒç”¨æ­¤å·¥å…·ã€‚

        Args:
            hours (int): æ€»ç»“è¿‡å»å¤šå°‘å°æ—¶çš„æ¶ˆæ¯ã€‚é»˜è®¤ä¸º 24ã€‚
        """
        # Tool çš„æ‰§è¡Œç»“æœéœ€è¦é€šè¿‡ yield è¿”å›ç»™ç”¨æˆ·
        # æœ€åçš„ return å­—ç¬¦ä¸²ä¼šä½œä¸º Tool Output ç»™ LLM
        async for result in self._summary_logic(event, hours=hours):
            yield result